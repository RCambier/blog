{
  
    
        "post0": {
            "title": "Gradient Boosting trees",
            "content": "Boosting trees . from sklearn.datasets import load_wine, load_breast_cancer import pandas as pd import numpy as np from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor from sklearn.model_selection import cross_val_score from sklearn.metrics import f1_score . raw = load_breast_cancer(return_X_y=True) X = pd.DataFrame(raw[0]) y = pd.DataFrame(raw[1]) . initial_prediction_proba = y.mean() initial_prediction_classes = round(initial_prediction_proba) initial_prediction_logodds = np.log(initial_prediction_proba / (1-initial_prediction_proba)) gradient_of_loss = 2 * (y - initial_prediction_proba).values.reshape(-1) print(&quot;Score with mean: &quot;, f1_score(y, [initial_prediction_classes[0]]*len(y))) learning_rate = 0.3 trees = [] for i in range(5): # Train a tree on the latest residuals tree = DecisionTreeRegressor(max_depth=1) tree.fit(X, gradient_of_loss) trees.append(tree) # Compute the predictions of the trees predictions = np.array(y.mean()) for tree in trees: predictions = predictions + learning_rate * tree.predict(X).reshape(-1) # Each tree tries to predict the error. # Get the new residuals. This is what we fit the next tree on # Residuals are the gradient of the loss with respect to the previous trees predictions. # In this case the loss is MSE: # loss = (y_hat - y) ** 2 # loss_gradient_with_respect_to_y = - 2 * (y_hat - y) = 2 * (y - y_hat) gradient_of_loss = 2* (y.values.reshape(-1) - predictions) predictions = np.array(y.mean()) for tree in trees: predictions = learning_rate * tree.predict(X).reshape(-1) + predictions print(&quot;Score with boosting: &quot;, f1_score(y, 1 * (predictions &gt; 0.5))) . Score with mean: 0.7710583153347732 Score with boosting: 0.947945205479452 .",
            "url": "https://rcambier.github.io/blog/ai/2021/09/18/boosting-trees.html",
            "relUrl": "/ai/2021/09/18/boosting-trees.html",
            "date": " ‚Ä¢ Sep 18, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Bayesian inference",
            "content": "import scipy as sp import numpy as np from scipy.stats import norm, binom import matplotlib.pyplot as plt import pymc3 . Bayesian inference . fake_observed = sp.stats.norm(46, 9).rvs(size=28) fake_observed.mean(), fake_observed.std() . (45.48803701443949, 8.076116332902322) . possible_probabilities_mean = np.linspace(0,100,100) prior_mean = norm.pdf(possible_probabilities_mean, loc=60, scale=20) prior_std = 9 plt.plot(prior_mean, label=&quot;prior&quot;) likelihood_mean = norm.pdf(fake_observed.mean(), loc=possible_probabilities_mean, scale=9) plt.plot(likelihood_mean, label=&quot;likelihood&quot;) posterior_unnormalized = prior_mean * likelihood_mean posterior = posterior_unnormalized / posterior_unnormalized.sum() plt.plot(posterior, label=&quot;posterior&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7fe8c2038220&gt; . with pymc3.Model() as model: u_prior = pymc3.distributions.Uniform(&quot;u_prior&quot;, 0, 100) sigma_prior = pymc3.distributions.Uniform(&quot;sigma_prior&quot;, 0, 20) likelihood = pymc3.distributions.Normal(&quot;likelihood&quot;, mu=u_prior, sigma=sigma_prior, observed=[fake_observed]) trace = pymc3.sample() pymc3.traceplot(trace) . &lt;ipython-input-9-911acd9862e4&gt;:6: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning. trace = pymc3.sample() Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (4 chains in 4 jobs) NUTS: [sigma_prior, u_prior] . . 100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences] Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 14 seconds. &lt;ipython-input-9-911acd9862e4&gt;:8: DeprecationWarning: The function `traceplot` from PyMC3 is just an alias for `plot_trace` from ArviZ. Please switch to `pymc3.plot_trace` or `arviz.plot_trace`. pymc3.traceplot(trace) /Users/rodolphe_cambier/miniconda3/lib/python3.8/site-packages/arviz/data/io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context. warnings.warn( . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;u_prior&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;u_prior&#39;}&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma_prior&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma_prior&#39;}&gt;]], dtype=object) .",
            "url": "https://rcambier.github.io/blog/ai/2021/09/17/bayesian-inference.html",
            "relUrl": "/ai/2021/09/17/bayesian-inference.html",
            "date": " ‚Ä¢ Sep 17, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "SVD",
            "content": "import pandas as pd import numpy as np from scipy.linalg import eig raw = pd.read_csv(&quot;https://raw.githubusercontent.com/smanihwr/ml-latest-small/master/ratings.csv&quot;) user_item_interactions = raw.pivot(values=&quot;rating&quot;, columns=&quot;movieId&quot;, index=&quot;userId&quot;) user_item_interactions = user_item_interactions.fillna(0) . A = np.array([ [5,5,0,1], [5,5,0,0], [0,1,5,5], [0,0,5,5], [0,0,3,5] ]) # Get the singular vectors of V from the eigenvectors of the covariance matrix V_eigen_values, V_unordered = np.linalg.eig(A.T @ A) # We need to sort them by the magnitude of the eigenvalues idx_V = np.argsort(V_eigen_values)[::-1] V = V_unordered[:,idx_V] # Compute the singular vectors of U. We could also use the eingenvectors, but we need to base it on V to have the correct vector directions. # U_eigen_values, U = np.linalg.eig(A @ A.T) this is similar but leads to incorrect directions for the eigenvectors U = A @ V / np.linalg.norm(A @ V, axis=0) # The matrix D is the square root of the eigenvalues. D = np.sqrt(np.around(V_eigen_values[idx_V], decimals=10)) . np.around(np.matrix(U) @ np.diag(D) @ np.matrix(V.T), decimals=1) . array([[ 5., 5., -0., 1.], [ 5., 5., 0., -0.], [ 0., 1., 5., 5.], [-0., 0., 5., 5.], [ 0., -0., 3., 5.]]) . U_, D_, Vt_ = np.linalg.svd(A) np.around(np.matrix(U_) @ np.vstack((np.diag(D_), np.zeros((len(Vt_))))) @ np.matrix(Vt_), decimals=1) . array([[ 5., 5., -0., 1.], [ 5., 5., -0., -0.], [-0., 1., 5., 5.], [-0., 0., 5., 5.], [-0., 0., 3., 5.]]) . Truncated SVD . Truncate the SVD to 2 components by only keeping the two bigest eigenvalues . np.matrix(U[:, :2]) . matrix([[-0.23093819, -0.66810948], [-0.16863574, -0.68636674], [-0.59892473, 0.13274366], [-0.57986295, 0.20070102], [-0.47252267, 0.15693514]]) . np.around(np.matrix(U[:, :2]) @ np.diag(D[:2]) @ np.matrix(V[:,:2].T), decimals=1) . array([[ 5. , 5. , 0.3, 0.8], [ 5. , 5. , -0.2, 0.2], [ 0.3, 0.7, 4.7, 5.3], [-0.2, 0.2, 4.7, 5.3], [-0.1, 0.2, 3.8, 4.3]]) .",
            "url": "https://rcambier.github.io/blog/ai/2021/09/16/SVD.html",
            "relUrl": "/ai/2021/09/16/SVD.html",
            "date": " ‚Ä¢ Sep 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "PCA",
            "content": "PCA . The principal components are the eigenvectors+eigenvalues of the Covariance matrix of our data. . This is because we are looking for the &quot;Direction of stretching and how much streching happens&quot; regarding the variance of our data. . from sklearn.datasets import load_digits import seaborn as sns from sklearn.decomposition import PCA import pandas as pd import numpy as np digits = pd.DataFrame(load_digits()[&#39;data&#39;]) classes = load_digits(return_X_y=True)[1] . low_dim_digits = PCA(n_components=2).fit_transform(digits) sns.scatterplot(x=low_dim_digits[:,0], y=low_dim_digits[:,1], hue=classes) . &lt;AxesSubplot:&gt; . digits_normed = digits - digits.mean() # compute the covariance matrix cov_matrix = digits_normed.T @ digits_normed / len(digits_normed) # same as digits_normed.cov() eigen_values, eigen_vectors = np.linalg.eig(cov_matrix) eigen_values, eigen_vectors # Sort eigen values end eigen vectors sorted_index = np.argsort(eigen_values)[::-1] sorted_eigenvalue = eigen_values[sorted_index] sorted_eigenvectors = eigen_vectors[:,sorted_index] # Select the 2 best eigenvector_subset = sorted_eigenvectors[:, 0:2] X_reduced = np.dot(eigenvector_subset.transpose(), digits_normed.transpose()).transpose() sns.scatterplot(x=X_reduced[:,0], y=X_reduced[:,1], hue=classes) . &lt;AxesSubplot:&gt; .",
            "url": "https://rcambier.github.io/blog/ai/2021/09/15/pca.html",
            "relUrl": "/ai/2021/09/15/pca.html",
            "date": " ‚Ä¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Linear regression & Logistic regression",
            "content": "import scipy as sp import numpy as np import pandas as pd from sklearn.metrics import r2_score, precision_score, recall_score, log_loss from sklearn.linear_model import LinearRegression, Ridge import sklearn . Some data . df = pd.read_csv(&quot;https://rcambier.github.io/blog/assets/california_housing_train.csv&quot;) df = df[[&#39;housing_median_age&#39;, &#39;total_rooms&#39;, &#39;total_bedrooms&#39;, &#39;population&#39;, &#39;households&#39;, &#39;median_income&#39;, &#39;median_house_value&#39;]] . Linear Regression . scaled_df = (df - df.min()) / (df.max() - df.min()) X = scaled_df[[&#39;housing_median_age&#39;, &#39;total_rooms&#39;, &#39;total_bedrooms&#39;, &#39;population&#39;, &#39;households&#39;, &#39;median_income&#39;]].values y = scaled_df[&#39;median_house_value&#39;].values X_with_intercept = np.hstack((np.ones((len(X), 1)),X)) B = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ (X_with_intercept.T @ y.reshape(-1, 1)) print(&quot;Manual weights: &quot;, B.reshape(-1)) print(&quot;Manual score: &quot;, r2_score(y, (X_with_intercept @ B).reshape(-1))) . Manual weights: [-0.07556544 0.19769139 -1.56087573 1.32234017 -2.57610401 1.59516284 1.43606576] Manual score: 0.5713482748283873 . from sklearn.metrics import r2_score RSS = (((X_with_intercept @ B).reshape(-1) - y)**2).sum() # Squared distance from our new regression line TSS = ((y.mean() - y)**2).sum() # Squared distance from the mean r2 = 1 - RSS / TSS # How much distance did we gained ? Did we reduce the errors ? Are we closer to the actual point values ? r2, r2_score(y, (X_with_intercept @ B).reshape(-1)) . (0.5713482748283873, 0.5713482748283873) . Let&#39;s compare those results with sklearn linear regression . lr = LinearRegression().fit(X, y) print(&quot;&quot;) print(&quot;Sklearn weights: &quot;, [lr.intercept_] + lr.coef_.tolist() ) print(&quot;Sklearn score: &quot;, r2_score(y, lr.predict(X))) . Sklearn weights: [-0.07556543642855085, 0.19769138728528463, -1.560875734209466, 1.3223401715433833, -2.5761040065353327, 1.5951628411047127, 1.4360657609756604] Sklearn score: 0.5713482748283873 . Linear regression with regularization (Ridge regression) . Regularization is the action of adding to the loss, a term that contains the weight values. That way these terms are forced to stay small. This helps avoiding overfitting. . Let&#39;s look at the ordinary least sqaure loss and then add the square of each weight to build the regularized loss. Adding the square of each weight means we buil the Ridge regression loss. If we add the absolute value of each weight we build the Lasso regression loss. . loss = (((X_with_intercept @ B) - y.reshape(-1, 1)).T @ (X_with_intercept @ B) - y.reshape(-1, 1)).reshape(-1) regularized_loss = loss + 0.3 * B.T @ B loss, regularized_loss . (array([-4.07656752, -4.10378391, -4.11533025, ..., -4.15223732, -4.11553644, -4.13368069]), array([[-0.1053435 , -0.13255988, -0.14410623, ..., -0.18101329, -0.14431241, -0.16245667]])) . The way adding this loss impacts the formula is the following . scaled_df = (df - df.min()) / (df.max() - df.min()) X = scaled_df[[&#39;housing_median_age&#39;, &#39;total_rooms&#39;, &#39;total_bedrooms&#39;, &#39;population&#39;, &#39;households&#39;, &#39;median_income&#39;]].values y = scaled_df[&#39;median_house_value&#39;].values X_with_intercept = np.hstack((np.ones((len(X), 1)),X)) I = np.identity(X_with_intercept.shape[1]) I[0,0] = 0 B = np.linalg.inv(X_with_intercept.T @ X_with_intercept + 0.3 * I) @ (X_with_intercept.T @ y.reshape(-1, 1)) print(&quot;Manual weights: &quot;, B.reshape(-1)) print(&quot;Manual score: &quot;, r2_score(y, (X_with_intercept @ B).reshape(-1))) . Manual weights: [-0.07457501 0.19926227 -1.4614579 1.30386275 -2.31228351 1.40463349 1.42708759] Manual score: 0.5710213053584052 . lr = Ridge(alpha=0.3).fit(X, y) print(&quot;&quot;) print(&quot;Sklearn weights: &quot;, [lr.intercept_] + lr.coef_.tolist() ) print(&quot;Sklearn score: &quot;, r2_score(y, lr.predict(X))) . Sklearn weights: [-0.07457500943073836, 0.19926227134208827, -1.4614578956147966, 1.3038627486538301, -2.3122835137561593, 1.4046334910837222, 1.4270875901070914] Sklearn score: 0.5710213053584055 . Logistic Regression . For the logistic regression, we transform the X values in the same way but we add a sigmoid transform at the end in order to map to values between 0 and 1. . We can not use the normal form anymore for computing the weights. We have to resort to other techniques like gradient descent. . def sigmoid(x): return 1 / (1 + np.exp(-x)) def log_likelihood(y_hat, y_true): # Being far away from the correct class is penalized heavily. return - np.mean( y_true * np.log(y_hat) + (1-y_true) * np.log(1-y_hat) ) def gradient_sigmoid(x): sigmoid(X) * (1 - sigmoid(X)) def gradients(X, y, y_hat): # Loss = y * log(h) + (1 - y) * log(1-h) # where h = sigmoid(z) # and z = Xt @ B # deriv_loss_to_h = y / h - (1-y) / (1-h) = (y - h) / (h * (1 - h)) # deriv_h_to_z = sigmoid(h) * (1 - sigmoid(h)) # deriv_z_to_b = Xt # Though chain rule, final derivative # final_derivative = deriv_loss_to_h * deriv_h_to_z * deriv_z_to_b = x * (y - h) = x * (y - y_hat) dw = (1/len(X)) * (X.T @ (y_hat - y)) return dw . df[&#39;median_house_value_cat&#39;] = (df[&#39;median_house_value&#39;] &gt; 150_000).astype(int) scaled_df = (df - df.min()) / (df.max() - df.min()) X = scaled_df[[&#39;housing_median_age&#39;, &#39;total_rooms&#39;, &#39;total_bedrooms&#39;, &#39;population&#39;, &#39;households&#39;, &#39;median_income&#39;]].values y = df[&#39;median_house_value_cat&#39;].values X_with_intercept = np.hstack((np.ones((len(X), 1)),X)) B = np.random.normal(0, 0.1 ,(7, 1)) for i in range(50_000): y_hat = sigmoid(X_with_intercept @ B).reshape(-1) if i % 5000 == 0 or i ==0: print(&quot;loss: &quot;, log_likelihood(y_hat, y)) deltas = gradients(X_with_intercept, y, y_hat) B -= 0.3 * deltas.reshape(-1, 1) lr = sklearn.linear_model.LogisticRegression().fit(X, y) . loss: 0.6821755251690551 loss: 0.46252854158211454 loss: 0.4541283502467595 loss: 0.4510517001241438 loss: 0.4487185438489886 loss: 0.4466409644195144 loss: 0.44474208933519344 loss: 0.4429996946665173 loss: 0.4413999204051543 loss: 0.43993073757337586 . print(&quot;Manual weights: &quot;, B.reshape(-1)) print(&quot;Manual score: &quot;, precision_score(y, (sigmoid(X_with_intercept @ B).reshape(-1) &gt; 0.5).astype(int) ), recall_score(y, (sigmoid(X_with_intercept @ B).reshape(-1) &gt; 0.5).astype(int) ), ) print() print(&quot;Sklearn log loss: &quot;, log_loss(y, (sigmoid(X_with_intercept @ B).reshape(-1)))) print(&quot;Sklearn weights: &quot;, lr.intercept_.tolist() + lr.coef_.reshape(-1).tolist()) print(&quot;Sklearn score&quot;, precision_score(y, lr.predict(X)), recall_score(y, lr.predict(X)) ) . Manual weights: [ -4.74650191 2.09565859 -11.5802056 7.08212211 -3.00163538 8.00035044 18.85028779] Manual score: 0.8215249055925193 0.8514583915758084 Sklearn log loss: 0.43866521703018374 Sklearn weights: [-4.385273936252051, 1.9603353158729624, -10.78106293024599, 6.882196980429938, -2.868679885031378, 7.251350300146187, 17.41000987846787] Sklearn score 0.8186773905272565 0.8536949026185817 . The weights are not exactly the same but the performances are very similar. This is due to the randomness aspect of training through gradient descent. .",
            "url": "https://rcambier.github.io/blog/ai/2021/09/14/linear-regression.html",
            "relUrl": "/ai/2021/09/14/linear-regression.html",
            "date": " ‚Ä¢ Sep 14, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Hypothesis testing",
            "content": "Hypothesis testing . import scipy as sp import numpy as np . A typical statement . A particular brand of tires claims that its deluxe tire averages at least 50,000 miles before it needs to be replaced. From past studies of this tire, the standard deviation is known to be 8,000. A survey of owners of that tire design is conducted. From the 28 tires surveyed, the mean lifespan was 46,500 miles with a standard deviation of 9,800 miles. Using ùõº=0.05 , is the data highly inconsistent with the claim? . claim_pop_mean = 50_000 pop_std = 8000 # What we know of the sample n = 28 sample_mean = 46_500 sample_std = 9800 # The chances of Type 1 error we are ready to accept alpha = 0.05 . The question can be formulated as: . &quot;Compared to the mean of that population (50_000), how crazy is the sample mean (46_500) ? With an alpha of 0.05&quot; | . which becomes . &quot;Using the sample deviation of the mean of that population, how far is the sample mean ? With an alpha of 0.05&quot; | . which becomes . &quot;Is the sample mean further away than 1.64 times the standard error of that population ?&quot; | . # H0 =&gt; pop_mean &gt;= 50_000 # H1 =&gt; pop_mean &lt; 50_000 population_standard_error = 8000 / np.sqrt(28) # &quot;If you grab a random sample mean, how is it going to variate&quot; how_far_we_are_from_pop_mean = (46_500 - 50_000) / population_standard_error # How far is this specific sample mean from the population mean. . There are different ways to reject the null hypothesis. . We can look at wether we are smaller or not than 0.05. . how_far_we_are_in_z = sp.stats.norm.cdf(how_far_we_are_from_pop_mean) how_far_we_are_in_z . 0.010305579572800304 . In this case we are at 0.01, which means that in the distribution of sample means, we are so extreme that there is no way that the sample mean we observed actually came from the sample mean distribution that we built looking at the population. . Another way is to look at how far we go on the axis, not in term of percentage (like 0,05 being 5%) but in term of distance from the population mean. This would look like the following . how_far_we_are_from_pop_mean . -2.315032397181517 . To know if this is a value too extreme or not, we can compare it to how far 0.05 is on the same axis: . - sp.stats.norm.ppf(0.95) . -1.6448536269514722 . When you don&#39;t have the population standard deviation . Realistically however, you often don&#39;t have the population standard deviation. In this case, you need to estimate it from the sample. . Doing that is less accurate. In order to compensate a bit, we need to model the &quot;spread of sample means&quot; a bit differently. . Since normally we allow the sample mean to only go &quot;so far&quot; from the population mean. We will force it to be &quot;even a bit further&quot;. The way we do this is by using a &quot;heavy tail&quot; distribution for the sample mean. That way, the 0.05 mark will be further to the right or to the left, and we are forced to be a little bit more sure of ourselves before saying anything. . Let&#39;s use the sample problem as above, but pretend that we don&#39;t know that the population has a standard deviation of 8000. We are forced to use the 9800 that we discovered experimentally. . claim_pop_mean = 50_000 # pop_std = 8000 # we don&#39;t know this anymore # What we know of the sample n = 28 sample_mean = 46_500 sample_std = 9800 # The chances of Type 1 error we are ready to accept alpha = 0.05 # 1. How far is the sample_mean from the pop_mean ? # H0 =&gt; pop_mean &gt;= 50_000 # H1 =&gt; pop_mean &lt; 50_000 population_standard_error = 9800 / np.sqrt(28) # &quot;If you grab a random sample mean, how is it going to variate&quot; how_far_we_are_from_pop_mean = (46_500 - 50_000) / population_standard_error # How far is this specific sample mean from the population mean. how_far_we_are_in_z = sp.stats.t.cdf(how_far_we_are_from_pop_mean, df=n-1) how_far_we_are_in_z . 0.014225814767264972 . We still reject the null hypothesis. But notice how much less confident we are ! Even if the standard deviation we sample was exactly 8000 (like the population one), we would still be less confident than if we received the standard deviation through a trustful source. . This is the whole point of this T student distribution ! . Confidence interval . Confidence interval are only in the point of view of the sample we just took. . From that sample, let&#39;s just add a standard error on each side and see how far this goes. . how_much_we_allow_on_unit_normal_distrib = sp.stats.norm.ppf(0.95) sample_mean_standard_error = 9800 / np.sqrt(n) how_much_we_allow_in_problem_domain = how_much_we_allow_on_unit_normal_distrib * sample_mean_standard_error how_much_we_allow_in_problem_domain [46_500 - how_much_we_allow_in_problem_domain, 46_500 + how_much_we_allow_in_problem_domain] . 3046.311548011343 .",
            "url": "https://rcambier.github.io/blog/ai/2021/09/13/hypothesis-testing.html",
            "relUrl": "/ai/2021/09/13/hypothesis-testing.html",
            "date": " ‚Ä¢ Sep 13, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Three‚Äòs a Crowd",
            "content": "From: http://www.twinbear.com/riddles.html . (Clayton Lewis) After solving the riddle of the three wise folks, three scoundrels claim to be the smartest in the country. So you decide to give them a challenge. Suspecting that the thing they care about most is money, you give them $100 and tell them they are to divide this money observing the following rule: they are to discuss offers and counter-offers from each other and then take a vote. Majority vote wins. Sounds easy enough‚Ä¶ now the question is, assuming each person is motivated to take the largest amount possible, what will the outcome be? . Note: careful‚Ä¶ if the answer were that they split it 50% / 50% / 0%, or 1/3 / 1/3 / 1/3, it wouldn‚Äòt be a riddle! . Note: careful‚Ä¶ 96.6523544 % of people who send answers to this have not thought about it for even 1 minute. I guarantee you won‚Äòt solve it in a minute. (96.6523544% of the time this guarantee is correct.) . Hover to show the answer. . I can not solve this one so far. If you can please share your answer! .",
            "url": "https://rcambier.github.io/blog/riddle/2021/01/05/scoundrels.html",
            "relUrl": "/riddle/2021/01/05/scoundrels.html",
            "date": " ‚Ä¢ Jan 5, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "The newcomb poison",
            "content": "You are put into a room with a suitcase and a flask of poison. . The suitcase has been filled either with 1 million dollar or with worthless magazines. . The poison is bad enough that you would never drink it for free, but it will not kill you. You would definitely drink it for 1 million dollar. It is going to give you a few days of headaches and feeling very ill. . Wether the suitace contains money or magazines depends on a prediction that was made by a machine. . If the machine predicts that you will drink the poison, the suitcase will contain the money | If the machine predicts that you will not drink the poison, the suitcase will be full of magazines. | . From more than 10 000 past experiments, we know that the machine has 95% accuracy on both cases. . You are now in the room. The prediction has been made on you and the suitcase has been filled accordingly. . Do you drink the poison and open the suitcase ? Or do you open the suitcase right away ? . Note: This is taken from Mr Phi video serie where he discusses the NewComb Paradox . Hover to show the answer. . My understanding at this time (early 2021) is the following: As a human being, you can not make a plan and stick to it. This would mean inhibiting your rationality. This is something that, unfortunately, we can not do. . So even if you 100% plan to drink the poison, you will doubt that decision once you are in the room. . I think I am not able to stick to a plan of drinking the poison. Therefore, I think I would not drink the poison and go straight for the suitcase. . This is concluding that there is no way for me to win the money. . Someone that could inhibit his rationality and stick to a plan could win the money. Someone not thinking about it too much and going for the poison could win the money. But as soon as you think too much about it, you understand that there is no way you actually drink the poison once you are in the room. . To help explain it: . The extreme case of a transparent suitcase. In that case, everyone will have to answer that they don‚Äôt drink the poison. | The extreme case of someone that can turn off his rationality. That person will be able to stick to his plan of drinking and actually win the money. But this is not possible for a normal human being. Look for the ‚Äúfatality of rationality‚Äù for this concept. | . | .",
            "url": "https://rcambier.github.io/blog/riddle/2021/01/05/newcomb.html",
            "relUrl": "/riddle/2021/01/05/newcomb.html",
            "date": " ‚Ä¢ Jan 5, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "The blind pill",
            "content": "You are blind. You have 2 blue pills and 2 red pills in a box. . You have to take 2 pills today and 2 tomorrow. Each day, exactly one blue and one red. If you don‚Äôt, you will die. If you take more, you will die. . How do you do it ? . Hover to show the answer. . One by one, you take the pill, break it in half, eat a half and keep the other half for tomorrow. This way, you will eat exactly 1 blue and 1 red pill per day. .",
            "url": "https://rcambier.github.io/blog/riddle/2020/07/29/pills.html",
            "relUrl": "/riddle/2020/07/29/pills.html",
            "date": " ‚Ä¢ Jul 29, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "The rope triangle",
            "content": "You cut a rope in a random place. Then again in another random place. . You are left with 3 pieces. . What are the chances that you can form a triangle with those 3 pieces ? . Hover to show the answer. . 1/4. .",
            "url": "https://rcambier.github.io/blog/riddle/2020/04/19/rope-triangle.html",
            "relUrl": "/riddle/2020/04/19/rope-triangle.html",
            "date": " ‚Ä¢ Apr 19, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Reversed number",
            "content": "Can you find a 4 digits number that gets reversed when multiplied by 4? . For example: if 4*1234 == 4321, 1234 would be an answer. Unfortunately, that is not the case. All digits need to be different. . Hover to show the answer. . 2178. .",
            "url": "https://rcambier.github.io/blog/riddle/2020/04/19/reverse-number.html",
            "relUrl": "/riddle/2020/04/19/reverse-number.html",
            "date": " ‚Ä¢ Apr 19, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a ‚Äúlevel 1 heading‚Äù in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here‚Äôs a footnote 1. Here‚Äôs a horizontal rule: . . Lists . Here‚Äôs a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes ‚Ä¶and‚Ä¶ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.¬†&#8617; . |",
            "url": "https://rcambier.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " ‚Ä¢ Jan 14, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Surprise birthday",
            "content": "Albert and Bernard just become friends with Cheryl, and they want to know when her birthday is. Cheryl gives them a list of 10 possible dates. . May 15 | May 16 | May 19 | June 17 | June 18 | July 14 | July 16 | August 14 | August 15 | August 17 | . Chely then tells Albert and Bernard separately the month and the day of her birthday respectively. . Albert: I don‚Äôt know when Cheryl‚Äôs birthday is, but I know that Bernard does not know too. . Bernard: At first I don‚Äôt know when Cheryl‚Äôs birthday is, but I know now. . Albert: Then I also know when Cheryl‚Äôs birthday is. . So when is Cheryl‚Äôs birthday ? . Hover to show the answer. . It is the July 16 . Albert (A) knows the month. | Bernard (B) knows the day. | If A knows the month and knows that B doesn‚Äôt know, it means that it is a month that only contains day that you can also find in other proposed months. Otherwise A wouldn‚Äôt be so sure that B doens‚Äôt know. So it cannot be May because if it was May 19, B would know. It cannot be June, because if it was June 18, B would know. It can be July or August. | B says he now knows when the birthday is. B just deduced, like us, that it could be July or August because of what A just said. If he now knows when it is, it cannot be the 14. So it is the July 16, August 15 or August 17. | A then says that he also now knows. So it has to be the July 16, since that is the only month where A has enough information to know the exact birthdate. If it was August, A would still need more information to differentiate between August 15 and August 17. | .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/26/surprise-birthday.html",
            "relUrl": "/riddle/2018/12/26/surprise-birthday.html",
            "date": " ‚Ä¢ Dec 26, 2018"
        }
        
    
  
    
        ,"post13": {
            "title": "Simple Maths",
            "content": "How do you make 26 by using 5, 5, 5 and 1. You have to use each exactly once. You can use the basic math operations (+, -, *, /, (, ) ). . Hover to show the answer. . (5 + (1/5))*5 = 26 .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/26/simple-maths.html",
            "relUrl": "/riddle/2018/12/26/simple-maths.html",
            "date": " ‚Ä¢ Dec 26, 2018"
        }
        
    
  
    
        ,"post14": {
            "title": "Potatoes",
            "content": "A farmer has 100kg of potatoes. At the start, they are composed of 99% of water (the water is 99% of the total weight) and 1% of dry matter (the dry matter is 1% of the total weight). Later, during storage and because of evaporation, the water percentage drops to 98%. What is the total weight of the potatoes then? . Hover to show the answer. . 50kg. . At the start, there are 99kg of water and 1kg of dry matter. Later, the quantity of dry matter didn‚Äôt change, but it is now representing 2% of the total mass. If 1kg is 2%, then 100% is 50kg. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/26/potatoes.html",
            "relUrl": "/riddle/2018/12/26/potatoes.html",
            "date": " ‚Ä¢ Dec 26, 2018"
        }
        
    
  
    
        ,"post15": {
            "title": "4 Pieces",
            "content": "There are 4 coins on a quadrant. They are not visible to you. . . If the 4 coins are heads or the four coins are tails, the center light will light up. You have 5 turns to make the center light light up. Each turn, you can choose 2 coins that you reveal (you see if they are heads or tails) and you can flip any of them if you want to. You can flip one, both, or none. After that, they are hidden back from you. After each turn, we spin the quadrant so fast that you can not keep track of wich two coins you interacted with last turn. If the coins are randomly initialized, what strategy allows you to be sure to turn the light on ? . Hover to show the answer. . By following this strategy, you will be sure to turn on the light. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/26/4-pieces.html",
            "relUrl": "/riddle/2018/12/26/4-pieces.html",
            "date": " ‚Ä¢ Dec 26, 2018"
        }
        
    
  
    
        ,"post16": {
            "title": "Running in circle",
            "content": "If I can make it around a running track once by going 10 km/h, what speed should I be running a second lap to have an average speed of 20 km/h for the two laps ? . Hover to show the answer. . This is impossible, I need to be infinitely fast. . Imagine a 10km track. It will take me 1 hour to make a lap at 10km/h. With a second lap, it becomes 20km. To have a 20km/h average speed, I need to do those 2 laps in 1 hour. . But I already spent 1 hour, so I should be infinitely fast for the second lap, which is impossible. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/running-in-circle.html",
            "relUrl": "/riddle/2018/12/25/running-in-circle.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post17": {
            "title": "Prisoner's switch",
            "content": "The warden meets with 23 new prisoners when they arrive. He tells them, ‚ÄúYou may meet today and plan a strategy. But after today, you will be in isolated cells and will have no communication with one another. . ‚ÄúIn the prison there is a switch room which contains two light switches labeled A and B, each of which can be in either the ‚Äòon‚Äô or the ‚Äòoff‚Äô position. BOTH SWITCHES ARE IN THEIR OFF POSITIONS NOW.* The switches are not connected to anything. . ‚ÄúAfter today, from time to time whenever I feel so inclined, I will select one prisoner at random and escort him to the switch room. This prisoner will select one of the two switches and reverse its position. He must move one, but only one of the switches. He can‚Äôt move both but he can‚Äôt move none either. Then he‚Äôll be led back to his cell.‚Äù . ‚ÄúNo one else will enter the switch room until I lead the next prisoner there, and he‚Äôll be instructed to do the same thing. I‚Äôm going to choose prisoners at random. I may choose the same guy three times in a row, or I may jump around and come back.‚Äù . ‚ÄúBut, given enough time, everyone will eventually visit the switch room as many times as everyone else. At any time any one of you may declare to me, ‚ÄòWe have all visited the switch room.‚Äô . ‚ÄúIf it is true, then you will all be set free. If it is false, and somebody has not yet visited the switch room, you will be fed to the alligators.‚Äù . *note - the only difference from Scenario B, the original position of the 2 switches are known. . Hover to show the answer. . The strategy is the following: . They choose one prisoner that will be the counter. Let‚Äôs name the two switches A and B. The counter is the only prisoner allowed to turn switch A off. When the other prisoner enter the room, if they have never done it, and if the switch A is off, they put it to ON. If they already put the A switch to ON or if they enter en the A switch is ON, they simply switch the B switch, in whatever position. . The counter will be able to count the number of prisoner that have entered the room by counting the number of times he has to put the A switch to OFF. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/prisoners-switch.html",
            "relUrl": "/riddle/2018/12/25/prisoners-switch.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post18": {
            "title": "King's poison",
            "content": "In a far away land, it was known that if you drank poison, the only way to save yourself is to drink a stronger poison in the next 12 hours, which neutralizes the weaker poison. . The king that ruled the land wanted to make sure that he possessed the strongest poison in the kingdom, in order to ensure his survival, in any situation. So the king called the kingdom‚Äôs pharmacist and the kingdom‚Äôs treasurer, he gave each a week to make the strongest poison. Then, each would drink the other one‚Äôs poison, then his own, and the one that will survive, will be the one that had the stronger poison. . The pharmacist went straight to work, but the treasurer knew he had no chance, for the pharmacist was much more experienced in this field, so instead, he made up a sneaky plan to survive and make sure the pharmacist dies. . On the last day the pharmacist suddenly realized that the treasurer would know he had no chance, so he must have a plan. After a little thought, the pharmacist realized what the treasurer‚Äôs plan must be, and he concocted a counter plan, to make sure he survives and the treasurer dies. When the time came, the king summoned both of them. They drank the poisons as planned, the treasurer died, and the pharmacist survived. . What happened ? What was the treasurer‚Äôs plan ? What was the pharmacist counter-plan ? And did the king get what he wanted ? . . Hover to show the answer. . The treasurer‚Äôs plan was to drink a weak poison before going to the king‚Äôs challenge, and bring water to the challenge. In front of the king, he would drink the strong pharmacist‚Äôs poison, which would neutralize his, and then drink the water he brought. On the opposite, the pharmacist would drink water, followed by his own poison, and then die. . When the pharmacist realises that, he decides to also bring water. That way he drinks water both times, and the treasurer dies from his weak poison. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/poison.html",
            "relUrl": "/riddle/2018/12/25/poison.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post19": {
            "title": "Lost father",
            "content": "Question: A mother is 21 years older than her child. In 6 years the mother will be 5 times older than her baby. . Where is the father? . Hover to show the answer. . M = mother | C = child . | M = C + 21 | M + 6 = 5* (C + 6) . | Solving gives C = -3/4 | -3/4 year means minus 9 months. If the child is -9 months, it means that the father is with the mother, in their bed‚Ä¶ | .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/lost-father.html",
            "relUrl": "/riddle/2018/12/25/lost-father.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post20": {
            "title": "Gold coins",
            "content": "There is a stack of 100 coins. Each coin has a silver side and a golden side. 20 coins are silver side up. The rest is golden side up. You are in a totally dark room. How do you make 2 stacks that contain as many coins with silver side up ? (we don‚Äôt care about how many are golden side up in each group) There is no way to differentiate the coins in the dark (by touch or other means.) . Hover to show the answer. . You take 20 coins from the stack and flip them to create another stack. The two stacks are the original stack withtout the 20 coins, and the stack of 20 coins you created. . If the 20 coins you select are golden side up, then you will flip them and have 20 silver coins in each stack. . If the 20 coins you select are silver side up, then you will flip them and have 0 silver coins in each stack. . If the 20 coins you select contain n silver and 20-n gold coins, then you will flip them and have 20-n silver coins in each stack. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/gold-coins.html",
            "relUrl": "/riddle/2018/12/25/gold-coins.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post21": {
            "title": "Cats and mouses",
            "content": "If 3 cats take 3 minutes to catch 3 mouses, how many cats are needed to catch 100 mouses in 100 minutes ? . . Hover to show the answer. . You also need 3 cats. . If 3 cats take 3 minutes to catch 3 mouses, it means each cat takes 3 minutes to catch its own mouse. In 100 minutes, each of those cats will catch on average 33.333‚Ä¶ mouses. So 3 cats are enough to catch 100 mouses in 100 minutes. . Said differently, if 3 cats take 3 minutes to catch 3 mouses, these 3 cats catch 1 mouse/minute. At that rate, they will capture 100 mouses in 100 minutes. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/cats-and-mouses.html",
            "relUrl": "/riddle/2018/12/25/cats-and-mouses.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post22": {
            "title": "Broken plane",
            "content": "Imagine a 747 is sitting on a conveyor belt, as wide and long as a runway. The conveyor belt is designed to [try to ?] exactly match the speed of the wheels, moving in the opposite direction. Can the plane take off? (different answers if you consider the words between brackets or not) . Hover to show the answer. . Yes. (Please don‚Äôt hit me). . If by speed of the wheels, we consider the speed of the the center of the wheels relative to the ground, then the answer is yes. The plane doesn‚Äôt use its wheel to take off. The motor thrust don‚Äôt care that the wheels are spinning or sliding or doing nothing. You have to realize that this is not like a car, the force is no pushing at the wheels, the force making the plane go forward is pushing where the motors are attached. So the wheels are just going to spin faster, and if the conveyor belt is long enough, the plane will take off. . Another way to see it is that the wheels are just there to keep the plane above the ground. They can spin at the speed they want, if the plane can move forward, it will take off. . Now, if by speed of the wheels, we consider the angular speed of the wheels then it gets complicated. This would basically be like saying ‚Äúthe conveyor belt does everything possible to make the plane not move‚Äù. . At that point, if the plane moves forward, the problem becomes mathematically impossible. When the plane is not moving, the angular speed is 0. When the plane moves, the angular speed is, let‚Äôs say, 10 ms/s. Now if the conveyor belt matches that speed, it will spin at 10m/s. But since the plane is still moving forward, this will make the wheels go at 20m/s (We consider here that the friction of the wheels is 0, they don‚Äôt affect the plane). So now the conveyor belt will have to match that speed. If the conveyor belt just tries to match the angular speed of the wheels, it will just go faster and faster up to infinity. If the friction of the wheels is 0, you could still argue in that situation that the plane will take off, with the wheel spinning infinitely fast in the opposite direction. . If the friction of the wheels is bigger than 0, you could argue that the threadmill manages to stop the plane. . If instead of the treadmill ‚Äútrying to match‚Äù you have the treadmill ‚Äúexactly matching‚Äù the speed of the wheels, than this becomes impossible. As soon as the plane starts going forward, this becomes an impossible situation because the treadmill has to match a speed that grows as it would try to match it. . Note that it doesn‚Äôt mean that the plane does not take off, but that the problem is mathematically impossible. . You can have a look at the excellent explanation from Randall Monroe on this problem here .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/25/broken-plane.html",
            "relUrl": "/riddle/2018/12/25/broken-plane.html",
            "date": " ‚Ä¢ Dec 25, 2018"
        }
        
    
  
    
        ,"post23": {
            "title": "Lost in the woods",
            "content": "You are in a square forest of side 100km. You are 2km away from its border, but you don‚Äôt know in what direction or at what angle (It could be at 2km with an angle of 16.123 degree for example.) You need to exit the forest, but you can walk a maximum of 13km. What path do you follow ? . Hover to show the answer. . Click the link to view an example of a path shorter than 13 km. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/18/lost-in-the-woods.html",
            "relUrl": "/riddle/2018/12/18/lost-in-the-woods.html",
            "date": " ‚Ä¢ Dec 18, 2018"
        }
        
    
  
    
        ,"post24": {
            "title": "Evil professor",
            "content": "The evil professor says to the students: you are going to have an exam next week. I‚Äôm not telling you which day, but I am telling you that it will be unexpected (i.e., the day of the exam you won‚Äôt be sure whether the exam is that day or not). I‚Äôm assuming that the week starts on Monday and ends on Friday. . So this is what the students think: . Okay, it can‚Äôt be on Friday, because if Friday comes and we haven‚Äôt had the test yet, then in the morning we‚Äôll surely know it‚Äôs that day. So it will be a day from Monday to Thursday. After pondering a bit, they realise that it can‚Äôt be Thursday either, for the same reason: If Thursday comes and they haven‚Äôt had the exam they‚Äôll think ‚Äúwe know it‚Äôs not Friday, therefore it has to be today‚Äù. So Thursday wouldn‚Äôt be a surprise either. Similarly (by induction), all days are eliminated ! . Then they are happy and think the evil professor made a promise he couldn‚Äôt hold, and don‚Äôt prepare for the test. However, the next week, on Wednesday, they have the exam. And all are surprised. . Where is the flaw in the logic ? . Hover to show the answer. . There is no answer to this‚Ä¶ I will try to explain later. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/18/evil-professor.html",
            "relUrl": "/riddle/2018/12/18/evil-professor.html",
            "date": " ‚Ä¢ Dec 18, 2018"
        }
        
    
  
    
        ,"post25": {
            "title": "Lighter",
            "content": "You have a lighter and two lengths of rope that burn for exactly 1 hour each. They do not burn consistently so you cannot, for example, cut one in half and burn that. How can you use these two ropes to measure exactly 45 minutes ? . Hover to show the answer. . Light one rope from both ends and one rope from one end. . After 30 minutes, the first rope will be finished burning. . You have 30 minutes left of burning on the second rope. Light the second end of that rope so that it will burn for 15 minutes instead of 30 minutes. . The total burning time will be 45 minutes. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/rope.html",
            "relUrl": "/riddle/2018/12/10/rope.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  
    
        ,"post26": {
            "title": "Prisoners and trees",
            "content": "Here is a logic puzzle that depends on the game theory concept of common knowledge. . Can you figure it out? Alice and Bob are taken prisoners by an evil logician. They are given one chance to be set free. Alice and Bob are placed in cells that have a view of a courtyard with trees. There are 20 trees in all, of which Alice sees 12 and Bob sees 8. Neither prisoner knows how many trees the other sees. But each prisoner is told the trees are partitioned between them: together they see all the trees, but individually no tree is seen by both of them. . . They have to figure out the total number of trees, but they are not allowed to communicate with each other. Each day the logician visits Alice in her cell and asks, ‚ÄúAre there 18 or 20 trees in total?‚Äù Alice has two choices: she can guess or pass. If Alice passes, then the logician visits Bob in his cell and asks the same question. Bob also can guess or pass. If Bob passes, then the logician retires for the night asks and repeats asking the questions the next day. Both prisoners know the procedure of how the logician is asking questions. There are consequences to guessing. If either person guesses incorrectly, then they are both trapped forever. If either person guesses correctly, however, then they are both set free immediately. Obviously they could guess and have a 50% chance. But can they do better? Is there a way they can escape with certainty? . Hover to show the answer. . This is a complex one. Answer is coming. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/prisoners-trees.html",
            "relUrl": "/riddle/2018/12/10/prisoners-trees.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  
    
        ,"post27": {
            "title": "Peeking",
            "content": "Jack is looking at Anne, but Anne is looking at George. Jack is married, but George is not. Is a married person looking at an unmarried person? . A: Yes | B: No | C: Cannot be determined | . Hover to show the answer. . Yes. . There are only two possible cases: either Anne is married, or she is not. . If she is married, then a married person (Jack) is looking at an unmarried person (Anne). If she is not married, then a married person (Anne) is looking at an unmarried person (George). .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/peeking.html",
            "relUrl": "/riddle/2018/12/10/peeking.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  
    
        ,"post28": {
            "title": "Exception",
            "content": "Find the exception . . Hover to show the answer. . B is the exception. . It is the only one that is only one difference away from every other one. . A and B have radius in difference | A and C have color in difference | A and D have snowfloake in difference | A and E have shape in diffrence | A and F have border in difference. | . If you select another one, like D, it can have 2 differences to some. .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/one-out.html",
            "relUrl": "/riddle/2018/12/10/one-out.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  
    
        ,"post29": {
            "title": "Magic logic",
            "content": "At a party last night, my friends Alice and Bob did a magic trick. Any ideas how it worked? . Alice shuffled a pack of cards, and asked me to take five. I looked at them. She put the rest of the pack down on the table. Alice asked for my cards. She had a look at them. She gave four of them to Bob (he was across the table), and the fifth back to me. Bob looked at the four cards for a while. Then Bob looked at me, and named the card I was holding. He was right. I‚Äôm quite sure he couldn‚Äôt have seen it (we weren‚Äôt sitting by a mirror). . They did the trick again later to someone else. I watched for funny business. Alice didn‚Äôt say anything to Bob, so I don‚Äôt think they have a code. Also Alice is famously clumsy, so I doubt it was sleight of hand. . . Hover to show the answer. . When Alice had the five cards in hands, she needs to find a way to select one, and communicate which one she selected to Bob by showing Bob the four other cards. . Here is the way to do that: . In the five cards, there are always two of the same suite. | Alice is going to chose one of those two and tell which one to Bob using the 3 remaining cards. | The thing to notice is: when having two cards of the same suite, they are alway 6 cards appart in some direction. For example 7-heart and 9-heart are 2 apart. But queen-spade and 2-spade are 3 apart: queen-king-ace-2. | Now since there are 12 different cards per suite, two cards are always going to be maximum 6 steps away from each other. | So the way to do it is: from the two cards of the same suite, pick the one that allows reaching the other by adding up to 6 steps. So with 7-heart and 9-heart, pick 7-heart. With 2-spade and queen-spade, pick queen-spade. | Let‚Äôs continue in the case where Alice picked the queen-spade. | Alice gives back to Bob 3 cards + the queen-spade on top. And Bob has to guess 2-spade. | The goal is now to make the number ‚Äò3‚Äô with the 3 remaining random cards. That way Bob knows he has to add ‚Äò3‚Äô to the queen-spade, which will give him the 2-spade. | This is easily doable. With 3 cards you can make 6 combinations. Just assign each of them to a number. | Here is a way to do this: The 3 cards can always be ordered by value. So you can have card-1, card-2 and card-3. The six orders could be: [1-2-3, 1-3-2, 2-1-3, 2-3-1, 3-1-2, 3-2-1]. Here we would select the order ‚Äò2-1-3‚Äô to represent the number 3. | So Bob sees the queen-spade, and then 3 cards that represent the number ‚Äò3‚Äô. He can now guess the 2-spade. | .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/magic-loop.html",
            "relUrl": "/riddle/2018/12/10/magic-loop.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  
    
        ,"post30": {
            "title": "Gender",
            "content": "A lady has two children. One is a boy. What are the chances of the other child also being a boy? . . Hover to show the answer. . This one is more complicated that I previously thought‚Ä¶ .",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/gender.html",
            "relUrl": "/riddle/2018/12/10/gender.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  
    
        ,"post31": {
            "title": "Blue eyes",
            "content": "A group of people with assorted eye colors live on an island. They are all perfect logicians ‚Äì if a conclusion can be logically deduced, they will do it instantly. No one knows the color of their eyes. Every night at midnight, a ferry stops at the island. Any islanders who have figured out the color of their own eyes then leave the island, and the rest stay. Everyone can see everyone else at all times and keeps a count of the number of people they see with each eye color (excluding themselves), but they cannot otherwise communicate. Everyone on the island knows all the rules in this paragraph. . On this island there are 100 blue-eyed people, 100 brown-eyed people, and the Guru (she happens to have green eyes). So any given blue-eyed person can see 100 people with brown eyes and 99 people with blue eyes (and one with green), but that does not tell him his own eye color; as far as he knows the totals could be 101 brown and 99 blue. Or 100 brown, 99 blue, and he could have red eyes. . The Guru is allowed to speak once (let‚Äôs say at noon), on one day in all their endless years on the island. Standing before the islanders, she says the following: . ‚ÄúI can see someone who has blue eyes.‚Äù . Who leaves the island, and on what night? . There are no mirrors or reflecting surfaces, nothing dumb. It is not a trick question, and the answer is logical. It doesn‚Äôt depend on tricky wording or anyone lying or guessing, and it doesn‚Äôt involve people doing something silly like creating a sign language or doing genetics. The Guru is not making eye contact with anyone in particular; she‚Äôs simply saying ‚ÄúI count at least one blue-eyed person on this island who isn‚Äôt me.‚Äù . And lastly, the answer is not ‚Äúno one leaves.‚Äù . Hover to show the answer. . All the 100 blue-eye people leave the island on the 100th night. . The following chart explains why using 4 people. The reflexion is the same, simply longer, for 100 persons. Click on the chart to open it in a new window. . The information &quot;There is at least one blue-eyed person&quot; is needed !The information &quot;There is at least one blue-eyed person&quot; is needed !If I am blue-eyed, he looks at 3 blue-eyed personsIf I am blue-eyed, he looks at 3 blue-eyed personsIf I am brown eyed, he looks at only 2 other blue-eyedIf I am brown eyed, he looks at only 2 other blue-eyedWhen I look at 3 blue-eyed person, I wonder if I am myself blue eyed.When I look at 3 blue-eyed person, I wonder if I am myself blue eyed.I consider myself blue-eyedI consider myself blue-eyedI consider myself brown-eyedI consider myself brown-eyedMEMEI wonder if this guy thinks he is blue eyed or not (I wonder the same for the 2 other, the reflexion is the same)[Not supported by viewer]MEMEAABBCCHe considers himself blue-eyedHe considers himself blue-eyedHe considers himself brown-eyedHe considers himself brown-eyedMEMEAABBCCIf A considers himself blue-eyed, there are 3 blue-eyed persons.If A considers himself blue-eyed, there are 3 blue-eyed persons.MEMEA[Not supported by viewer]BBCCIf A doesn&#39;t consider himself blue-eyed, he will try to understand what the 2 last one are going to do¬†[Not supported by viewer]This last guy could think he is brown-eyedThis last guy could think he is brown-eyedThis last guy could think he is blue-eyedThis last guy could think he is blue-eyedMEMEAABBCCThen there are 2 blue-eyed persons¬†Then there are 2 blue-eyed persons¬†MEMEAABBCCThen he looks at a blue-eye guy that is aloneThen he looks at a blue-eye guy that is aloneMEMEAABBCCIf someone comes and say &quot;There is at least one blue-eyed person&quot;, than person B will see 3 brown-eyed and leave ![Not supported by viewer]If someone comes and say &quot;There is at least one blue-eyed person&quot;, Than, no one will dare to leave the first day ![Not supported by viewer]After one day, we know which one of those 2 supposed situations is the true one.Either B left, and there was only 1 blue-eyed person.Or B stays, and C will understand that he is blue after one day.¬†[Not supported by viewer]However, if after two days, B and C are not leaving...A will understand that his supposition that he is brown might be false.The third day, A, B and C are going to leave[Not supported by viewer]If the 3rd day no one leaves..¬†I should understand that the supposition that I am brown can not hold.¬†Therefore, we are all blue-eyed.The 4th day, we all leave.[Not supported by viewer]The problem is the same with 4 persons and with 100 persons.This is the concept of common-knowledge.¬†At first, I might think that it is common knowledge that there are at least 3 blue-eyed person. And I might think that the sentence &quot;there is at least one blue-eyed person&quot; is useless, since everyone sees at least two blue eyed person.¬†But we don&#39;t all have the same knowledge. If I am browm eyed, other people might only see 2 blue-eyed persons. Those persons will think that other could only see 1 blue-eyed person. And those persons that see only one blue-eyed person could think that someone sees no blue-eyed persons.¬†This means that, until someone says &quot;I see at least one blue eyed person&quot; and 4 day passes, we don&#39;t all have the same knowledge about the world.The time it takes to reach common knowledge is the time the persons have to wait before leaving.¬†[Not supported by viewer]Yes this is comic sans ms :)Yes this is comic sans ms :)&lt;br&gt;",
            "url": "https://rcambier.github.io/blog/riddle/2018/12/10/blue-eyes.html",
            "relUrl": "/riddle/2018/12/10/blue-eyes.html",
            "date": " ‚Ä¢ Dec 10, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Ai from scratch",
          "content": "AI from scratch . When I learn about a new ML algorithm, the best way for me to understand it is to look at a very basic version written from scratch in Python. . This is a compilation of notebooks with very simple implementations of some ML algorithms. I try to only use numpy and scipy. . The goal is not to explain or teach. It&#39;s to capture the essence in a few simple lines of Python. If you find mistakes please mention it! . Gradient Boosting trees Simple boosting trees in python from scratch Bayesian inference Bayesian inference in python from scratch SVD Singular value decomposition from scratch PCA PCA dimensionality reduction from scratch Linear regression &amp; Logistic regression Linear regression, ridge regression, logistic regression with r2 score from scratch in Python Hypothesis testing Hypothesis testing, confidence interval",
          "url": "https://rcambier.github.io/blog/ai-from-scratch/",
          "relUrl": "/ai-from-scratch/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Riddles",
          "content": "Riddles . Riddles ! . I haven&#39;t invented any of those. I just found them online and thought they were good ones. . The riddles are ranked by some measure of difficulty. . Cats and mouses (difficulty 1) If 3 cats take 3 minutes to catch 3 mouses, ... &lt;/div&gt; Peeking (difficulty 1) Jack is looking at Anne, but Anne is looking... &lt;/div&gt; Potatoes (difficulty 1.5) A farmer has 100kg of potatoes. At the start... &lt;/div&gt; Simple Maths (difficulty 1.5) How do you make 26 by using 5, 5, 5 and 1. Y... &lt;/div&gt; Surprise birthday (difficulty 2) Albert and Bernard just become friends with ... &lt;/div&gt; Reversed number (difficulty 2) Can you find a 4 digits number that gets rev... &lt;/div&gt; The rope triangle (difficulty 2) You cut a rope in a random place. Then again... &lt;/div&gt; The blind pill (difficulty 2) You are blind. You have 2 blue pills and 2 ... &lt;/div&gt; Exception (difficulty 2) Find the exception . Gold coins (difficulty 2) There is a stack of 100 coins. Each coin has... &lt;/div&gt; Lighter (difficulty 2) You have a lighter and two lengths of rope t... &lt;/div&gt; Running in circle (difficulty 2) If I can make it around a running track once... &lt;/div&gt; Lost father (difficulty 2.5) Question: A mother is 21 years older than he... &lt;/div&gt; King&#39;s poison (difficulty 2.5) In a far away land, it was known that if you... &lt;/div&gt; 4 Pieces (difficulty 2.5) There are 4 coins on a quadrant. They are no... &lt;/div&gt; Prisoner&#39;s switch (difficulty 3) The warden meets with 23 new prisoners when ... &lt;/div&gt; Magic logic (difficulty 3) At a party last night, my friends Alice and ... &lt;/div&gt; Lost in the woods (difficulty 3.5) You are in a square forest of side 100km. Yo... &lt;/div&gt; Prisoners and trees (difficulty 4) Here is a logic puzzle that depends on the g... &lt;/div&gt; Blue eyes (difficulty 5) A group of people with assorted eye colors l... &lt;/div&gt; Broken plane (difficulty 10) Imagine a 747 is sitting on a conveyor belt,... &lt;/div&gt; The newcomb poison (difficulty 99) You are put into a room with a suitcase and ... &lt;/div&gt; Evil professor (difficulty 99) The evil professor says to the students: you... &lt;/div&gt; Gender (difficulty 99) A lady has two children. One is a boy. What ... &lt;/div&gt; Three‚Äòs a Crowd (difficulty 99) From: http://www.twinbear.com/riddles.html . &lt;/div&gt; . . . . .",
          "url": "https://rcambier.github.io/blog/riddles/",
          "relUrl": "/riddles/",
          "date": ""
      }
      
  

  
  

  
  

  
  

  
  

  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://rcambier.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}