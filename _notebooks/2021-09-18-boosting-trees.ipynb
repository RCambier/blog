{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "AI basics.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('scratch': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "1cd4112ee697feb47ec4321357aa333673c485b2f335328c935108ae8c7ab29f"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting trees\n",
        "> \"Simple boosting trees, for regression and classification in python from scratch\"\n",
        "\n",
        "- comments: true\n",
        "- badges: true\n",
        "- categories: [ai]\n",
        "- publishes: true"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boosting trees"
      ],
      "metadata": {
        "id": "cELsxC2Su_o8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from sklearn.datasets import load_wine, load_breast_cancer, load_boston\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, mean_absolute_error\n",
        "from sklearn.ensemble._gb_losses import BinomialDeviance"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q9iIbM3fnJiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "raw = load_boston(return_X_y=True)\n",
        "\n",
        "X = pd.DataFrame(raw[0])\n",
        "y = pd.DataFrame(raw[1])\n",
        "\n",
        "initial_predictions = [y.mean()[0]] * len(y)\n",
        "\n",
        "\n",
        "print(\"Error with mean: \", mean_absolute_error(y, initial_predictions))\n",
        "\n",
        "learning_rate = 0.3\n",
        "\n",
        "# Let's build some trees !\n",
        "predictions_so_far = initial_predictions\n",
        "gradient_of_loss = (y.values.reshape(-1) - predictions_so_far)\n",
        "trees = []\n",
        "for i in range(5): \n",
        "\n",
        "  # Train a tree on the latest residuals\n",
        "  tree = DecisionTreeRegressor(max_depth=1)\n",
        "  tree.fit(X, gradient_of_loss)\n",
        "  trees.append(tree)\n",
        "\n",
        "  # Compute the predictions of the trees\n",
        "  predictions_so_far = predictions_so_far + learning_rate * tree.predict(X).reshape(-1) # Each tree tries to predict the error. \n",
        "\n",
        "  # Get the new residuals. This is what we fit the next tree on\n",
        "  # Residuals are the gradient of the loss with respect to the previous trees predictions. \n",
        "  # In this case the loss is MSE: \n",
        "  # loss = (y_hat - y) ** 2\n",
        "  # loss_gradient_with_respect_to_y = - 2 * (y_hat - y) = 2 * (y - y_hat)\n",
        "  gradient_of_loss =  2* (y.values.reshape(-1) - predictions_so_far)\n",
        "\n",
        "print(\"Error with boosting: \", mean_absolute_error(y, predictions_so_far))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error with mean:  6.647207423956011\n",
            "Error with boosting:  3.3369627690621475\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSm5xGcCvY8T",
        "outputId": "7d61722f-0f00-4234-8542-71f70d45e5b8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from sklearn.datasets import load_wine, load_breast_cancer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q9iIbM3fnJiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def update_lead_values(tree): \n",
        "    "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "raw = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "X = pd.DataFrame(raw[0])\n",
        "y = pd.DataFrame(raw[1])\n",
        "\n",
        "p = y.mean()[0]\n",
        "initial_predictions = np.array([np.log(p/(1-p))] * len(y))# Initial prediction is logodds of y\n",
        "print(\"Initial score: \", f1_score(y, (initial_predictions > 0.5) *1))\n",
        "\n",
        "\n",
        "learning_rate = 0.3\n",
        "\n",
        "def sigmoid(x): \n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "y_hat = sigmoid(initial_predictions)\n",
        "gradient_of_loss = y_hat - y.values.reshape(-1)\n",
        "\n",
        "\n",
        "trees = []\n",
        "predictions_so_far = initial_predictions\n",
        "for i in range(5): \n",
        "\n",
        "  # Train a tree on the latest residuals\n",
        "  tree = DecisionTreeRegressor(max_depth=1)\n",
        "  tree.fit(X, gradient_of_loss)\n",
        "\n",
        "  # TODO: Here you need to update the values of the tree leaves\n",
        "  # to equal a specific value each. \n",
        "\n",
        "  trees.append(tree)\n",
        "\n",
        "  # Compute the predictions of the trees\n",
        "  predictions_so_far = predictions_so_far - learning_rate * tree.predict(X).reshape(-1) \n",
        "\n",
        "  # The gradient of the loss with respect to y_hat\n",
        "  # is y_hat - y. Neat.\n",
        "  y_hat = sigmoid(predictions_so_far)\n",
        "  gradient_of_loss =  y_hat - y.values.reshape(-1)\n",
        "\n",
        "print(\"Score with boosting: \", f1_score(y, 1 * (sigmoid(predictions_so_far) > 0.5)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial score:  0.7710583153347732\n",
            "Score with boosting:  0.922279792746114\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "trees[0].tree_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.tree._tree.Tree at 0x7faeec0f2180>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}