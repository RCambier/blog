{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python multiprocessing with loading bar\n",
    "> Create a nice multiprocessing logic with a loading bar\n",
    "\n",
    "- comments: true\n",
    "- badges: true\n",
    "- categories: [random]\n",
    "- publishes: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing in Python is already not the best. But on top of it, I always want to add a loading bar that tells me how much work has been performed. \n",
    "It took me a while to figure out how to best do that. \n",
    "\n",
    "What I want is: \n",
    "- Work gets done in parrallel, either in threads or in processes depending on how much GIL locking there is in my function. \n",
    "- The loading bar progresses as work gets done. \n",
    "- When the progress bars hits the end, work is finished.\n",
    "- You can pipe a generator into the parrallel processing, and it will be consumed progressively\n",
    "\n",
    "What I settled for is the below code. It consumes the `iterable` generator progressively, and displays a progress bar indicating how much work has been achieved. \n",
    "\n",
    "1. For multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "from tqdm.auto import tqdm \n",
    "import time\n",
    "\n",
    "def work_function(arg): \n",
    "    time.sleep(arg)\n",
    "    return arg\n",
    "\n",
    "def iterable():\n",
    "    for i in range(0,20):\n",
    "        time.sleep(i/10)\n",
    "        yield i\n",
    "\n",
    "with Pool(10) as p: \n",
    "    results = list(tqdm(p.imap(work_function, iterable(), chunksize=1)))\n",
    "    print(results)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For multithreading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from tqdm.auto import tqdm \n",
    "import time\n",
    "\n",
    "def work_function(arg): \n",
    "    time.sleep(arg)\n",
    "    return arg\n",
    "\n",
    "def iterable():\n",
    "    for i in range(0,20):\n",
    "        time.sleep(i/10)\n",
    "        yield i\n",
    "\n",
    "with Pool(10) as p: \n",
    "    results = list(tqdm(p.imap(work_function, iterable(), chunksize=1)))\n",
    "    print(results)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not use concurrent.futures ? \n",
    "\n",
    "Because this option does not allow for the `imap` multiprocessing. This means that all the iterable will be consumed before being sent to the workers. This could be fine, but sometimes, if the iterable takes time to compute or is a generator itself, you don't want to consume it fully before starting the concurrent processing. \n",
    "\n",
    "Try the code below. Notice that the loading bar starts appearing once the iterable has been consumed, which means it already reached the 13/20 iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm.auto import tqdm \n",
    "import time\n",
    "\n",
    "def work_function(arg): \n",
    "    time.sleep(arg)\n",
    "    return arg\n",
    "\n",
    "def iterable():\n",
    "    for i in range(0,20):\n",
    "        time.sleep(i/10)\n",
    "        yield i\n",
    "\n",
    "with ProcessPoolExecutor(10) as p: \n",
    "    results = list(tqdm(p.map(work_function, iterable(), chunksize=1)))\n",
    "    print(results)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about tqdm process_map ?\n",
    "\n",
    "`tqdm.contrib.concurrent.process_map` is essentially the same as the concurrent.futures behind the scenes, and will exhibit the same behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
